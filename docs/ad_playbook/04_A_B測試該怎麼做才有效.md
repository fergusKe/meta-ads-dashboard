# A/B 測試該怎麼做才有效？

## 痛點情境
測試了很多版本卻沒有學習？資料散落在 Excel、Slack，結果無法量化，也很難說服客戶調整。

## 我們的解法
1. **A/B 測試控制台** 集中建立實驗、紀錄變體與指標結果。
2. **CopywritingAgent / ImagePromptAgent** 快速生成不同角度的素材，並附上測試建議。
3. **Agent 執行歷史** 自動寫入每次生成與採納情況，方便回顧。
4. **匯出工具** 一鍵產出 JSON/CSV 報告，供客戶簡報或內部檢討。

### 核心流程
1. 在控制台建立實驗（命名、變體描述、預期目標）。
2. 用 AI 生成創意或受眾變體，並記錄在控制台。
3. 投放後回填轉換、CTR 等指標，控制台自動保存成功率。
4. 利用匯出功能或歷史紀錄，產出「這次測試的學習清單」。

### 推薦工具
- `pages/29_🧪_A_B_測試控制台.py`
- `utils/experiments.py`
- `pages/30_📜_Agent執行歷史.py`
- `utils/exporter.py`

### 監控指標
- 各變體 CTR / CPA / ROAS / CVR
- 實驗勝出率與採納率
- AI 生成 vs 人工版本的表現差異

## 後續可優化
- 自動計算統計顯著（樣本數、p-value）提醒是否結束實驗。
- 與 Meta API 對接，投放結果自動回填控制台。
- 建立「學習庫」，將每次實驗重點沉澱成最佳實務。
