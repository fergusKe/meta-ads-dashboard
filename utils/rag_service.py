"""
RAG (Retrieval-Augmented Generation) Service
ç”¨æ–¼å¾æ­·å²æ•¸æ“šä¸­æª¢ç´¢ç›¸é—œæ¡ˆä¾‹ï¼Œå¢å¼· LLM ç”Ÿæˆå“è³ª

ä¸»è¦åŠŸèƒ½ï¼š
1. å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆé«˜æ•ˆå»£å‘Šç´ æã€å„ªåŒ–æ¡ˆä¾‹ï¼‰
2. æª¢ç´¢ç›¸ä¼¼æ¡ˆä¾‹
3. å¢å¼· LLM Prompt
"""

import os
import json
from pathlib import Path
from typing import List, Dict, Optional, Any
import pandas as pd
from datetime import datetime

# LangChain imports
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

class RAGService:
    """RAG æœå‹™é¡åˆ¥"""

    def __init__(self, persist_directory: str = "./data/chromadb"):
        """
        åˆå§‹åŒ– RAG æœå‹™

        Args:
            persist_directory: å‘é‡è³‡æ–™åº«å„²å­˜è·¯å¾‘
        """
        self.persist_directory = persist_directory
        self.embeddings = None
        self.vectorstore = None

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        Path(persist_directory).mkdir(parents=True, exist_ok=True)

    def _get_openai_api_key(self) -> Optional[str]:
        """ç²å– OpenAI API Key"""
        # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸ç²å–
        api_key = os.getenv('OPENAI_API_KEY')

        if not api_key:
            # å˜—è©¦å¾ .env æª”æ¡ˆè®€å–
            env_file = Path(__file__).parent.parent / '.env'
            if env_file.exists():
                with open(env_file, 'r') as f:
                    for line in f:
                        if line.startswith('OPENAI_API_KEY='):
                            api_key = line.split('=', 1)[1].strip().strip('"\'')
                            break

        if not api_key:
            # å˜—è©¦å¾ Streamlit secrets ç²å–
            try:
                import streamlit as st
                api_key = st.secrets.get("OPENAI_API_KEY")
            except:
                pass

        return api_key

    def initialize_embeddings(self) -> bool:
        """
        åˆå§‹åŒ– OpenAI Embeddings

        Returns:
            æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        """
        api_key = self._get_openai_api_key()

        if not api_key:
            print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ° OPENAI_API_KEYï¼ŒRAG åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
            return False

        try:
            self.embeddings = OpenAIEmbeddings(
                model="text-embedding-3-small",  # ä½¿ç”¨è¼ƒä¾¿å®œçš„ embedding æ¨¡å‹
                openai_api_key=api_key
            )
            return True
        except Exception as e:
            print(f"âŒ Embeddings åˆå§‹åŒ–å¤±æ•—ï¼š{str(e)}")
            return False

    def create_ad_creative_knowledge_base(self, df: pd.DataFrame, collection_name: str = "ad_creatives"):
        """
        å»ºç«‹é«˜æ•ˆå»£å‘Šç´ æçŸ¥è­˜åº«

        Args:
            df: åŒ…å«å»£å‘Šæ•¸æ“šçš„ DataFrame
            collection_name: é›†åˆåç¨±
        """
        if not self.initialize_embeddings():
            raise ValueError("Embeddings æœªåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ API Key")

        # ç¯©é¸é«˜æ•ˆå»£å‘Šï¼ˆROAS >= 3.0ï¼‰
        high_performing_ads = df[df['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] >= 3.0].copy()

        if high_performing_ads.empty:
            print("âš ï¸ æ²’æœ‰æ‰¾åˆ°é«˜æ•ˆå»£å‘Šï¼ˆROAS >= 3.0ï¼‰")
            return

        # å»ºç«‹æ–‡æª”
        documents = []

        for idx, row in high_performing_ads.iterrows():
            # æå–é—œéµè³‡è¨Š
            headline = row.get('headline', 'æœªçŸ¥')
            body = row.get('å…§æ–‡', '')
            cta = row.get('call_to_action_type', 'æœªçŸ¥')
            roas = row.get('è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰', 0)
            ctr = row.get('CTRï¼ˆå…¨éƒ¨ï¼‰', 0)
            purchases = row.get('è³¼è²·æ¬¡æ•¸', 0)
            age = row.get('å¹´é½¡', 'æœªçŸ¥')
            gender = row.get('æ€§åˆ¥', 'æœªçŸ¥')

            # çµ„åˆæˆæ–‡æª”å…§å®¹
            content = f"""
ã€é«˜æ•ˆå»£å‘Šç´ æã€‘
Headlineï¼š{headline}
å…§æ–‡ï¼š{body[:200] if body else 'ç„¡'}
CTAï¼š{cta}

ã€æˆæ•ˆæŒ‡æ¨™ã€‘
ROASï¼š{roas:.2f}
CTRï¼š{ctr:.2f}%
è³¼è²·æ¬¡æ•¸ï¼š{purchases:.0f}

ã€å—çœ¾ã€‘
å¹´é½¡ï¼š{age}
æ€§åˆ¥ï¼š{gender}

ã€æˆåŠŸè¦ç´ åˆ†æã€‘
- Headline é•·åº¦ï¼š{len(str(headline))} å­—å…ƒ
- æ˜¯å¦åŒ…å«æ•¸å­—ï¼š{'æ˜¯' if any(char.isdigit() for char in str(headline)) else 'å¦'}
- æ˜¯å¦åŒ…å«å•è™Ÿï¼š{'æ˜¯' if '?' in str(headline) else 'å¦'}
- CTA é¡å‹ï¼š{cta}
"""

            # å»ºç«‹ metadata
            metadata = {
                'type': 'ad_creative',
                'headline': str(headline),
                'cta': str(cta),
                'roas': float(roas),
                'ctr': float(ctr),
                'purchases': int(purchases),
                'age': str(age),
                'gender': str(gender),
                'created_at': datetime.now().isoformat()
            }

            documents.append(Document(
                page_content=content,
                metadata=metadata
            ))

        # å»ºç«‹å‘é‡è³‡æ–™åº«ï¼ˆå…ˆåˆªé™¤èˆŠè³‡æ–™ï¼Œé¿å…é‡è¤‡ï¼‰
        print(f"ğŸ“š æ­£åœ¨å»ºç«‹çŸ¥è­˜åº«ï¼š{len(documents)} ç­†é«˜æ•ˆå»£å‘Šç´ æ...")

        # å˜—è©¦åˆªé™¤èˆŠçš„ collection
        try:
            import chromadb
            client = chromadb.PersistentClient(path=self.persist_directory)
            try:
                client.delete_collection(name=collection_name)
                print(f"ğŸ—‘ï¸ å·²åˆªé™¤èˆŠçš„ collection: {collection_name}")
            except:
                pass  # collection ä¸å­˜åœ¨ï¼Œå¿½ç•¥éŒ¯èª¤
        except:
            pass

        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            collection_name=collection_name,
            persist_directory=self.persist_directory
        )

        print(f"âœ… çŸ¥è­˜åº«å»ºç«‹å®Œæˆï¼å„²å­˜æ–¼ï¼š{self.persist_directory}")
        print(f"ğŸ“Š å¯¦éš›å„²å­˜æ–‡æª”æ•¸ï¼š{self.vectorstore._collection.count()}")

    def load_knowledge_base(self, collection_name: str = "ad_creatives"):
        """
        è¼‰å…¥ç¾æœ‰çŸ¥è­˜åº«

        Args:
            collection_name: é›†åˆåç¨±
        """
        if not self.initialize_embeddings():
            raise ValueError("Embeddings æœªåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ API Key")

        try:
            self.vectorstore = Chroma(
                collection_name=collection_name,
                embedding_function=self.embeddings,
                persist_directory=self.persist_directory
            )
            print(f"âœ… çŸ¥è­˜åº«è¼‰å…¥æˆåŠŸï¼š{collection_name}")
            return True
        except Exception as e:
            print(f"âŒ çŸ¥è­˜åº«è¼‰å…¥å¤±æ•—ï¼š{str(e)}")
            return False

    def add_documents(self, documents: List[Document], collection_name: str = "ad_creatives") -> None:
        """
        å‘æŒ‡å®šçŸ¥è­˜åº«è¿½åŠ æ–‡ä»¶ã€‚è‹¥æœªè¼‰å…¥å‰‡å˜—è©¦è¼‰å…¥ï¼Œç„¡å‰‡å»ºç«‹ã€‚
        """
        if not documents:
            return

        if not self.initialize_embeddings():
            raise ValueError("Embeddings æœªåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ API Key")

        if self.vectorstore is None:
            try:
                self.vectorstore = Chroma(
                    collection_name=collection_name,
                    embedding_function=self.embeddings,
                    persist_directory=self.persist_directory
                )
            except Exception:
                # è‹¥ collection ä¸å­˜åœ¨å‰‡å»ºç«‹æ–°çš„
                self.vectorstore = Chroma.from_documents(
                    documents=documents,
                    embedding=self.embeddings,
                    collection_name=collection_name,
                    persist_directory=self.persist_directory
                )
                return

        self.vectorstore.add_documents(documents)
        self.vectorstore.persist()

    def search_similar_ads(self, query: str, k: int = 5, filter_criteria: Optional[Dict] = None) -> List[Document]:
        """
        æœå°‹ç›¸ä¼¼å»£å‘Š

        Args:
            query: æœå°‹æŸ¥è©¢ï¼ˆä¾‹å¦‚ï¼šã€Œé«˜è½‰æ›ç‡çš„ Headlineã€ï¼‰
            k: è¿”å›çµæœæ•¸é‡
            filter_criteria: ç¯©é¸æ¢ä»¶ï¼ˆä¾‹å¦‚ï¼š{'roas': {'$gte': 4.0}}ï¼‰

        Returns:
            ç›¸ä¼¼æ–‡æª”åˆ—è¡¨
        """
        if not self.vectorstore:
            raise ValueError("çŸ¥è­˜åº«æœªè¼‰å…¥ï¼Œè«‹å…ˆèª¿ç”¨ load_knowledge_base()")

        try:
            if filter_criteria:
                results = self.vectorstore.similarity_search(
                    query=query,
                    k=k,
                    filter=filter_criteria
                )
            else:
                results = self.vectorstore.similarity_search(query=query, k=k)

            return results
        except Exception as e:
            print(f"âŒ æœå°‹å¤±æ•—ï¼š{str(e)}")
            return []

    def get_context_for_generation(self, query: str, k: int = 3) -> str:
        """
        ç²å–ç”¨æ–¼ç”Ÿæˆçš„ä¸Šä¸‹æ–‡

        Args:
            query: æŸ¥è©¢å…§å®¹
            k: æª¢ç´¢çµæœæ•¸é‡

        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ä¸²
        """
        similar_ads = self.search_similar_ads(query, k=k)

        if not similar_ads:
            return ""

        context = "**åƒè€ƒæ­·å²é«˜æ•ˆæ¡ˆä¾‹**ï¼š\n\n"

        for i, doc in enumerate(similar_ads, 1):
            context += f"### æ¡ˆä¾‹ {i}ï¼ˆROAS {doc.metadata.get('roas', 0):.2f}ï¼‰\n"
            context += f"{doc.page_content}\n\n"
            context += "---\n\n"

        return context

    def create_optimization_case_knowledge_base(self, cases: List[Dict], collection_name: str = "optimization_cases"):
        """
        å»ºç«‹å„ªåŒ–æ¡ˆä¾‹çŸ¥è­˜åº«

        Args:
            cases: å„ªåŒ–æ¡ˆä¾‹åˆ—è¡¨ï¼Œæ¯å€‹æ¡ˆä¾‹åŒ…å«ï¼š
                   - problem: å•é¡Œæè¿°
                   - solution: è§£æ±ºæ–¹æ¡ˆ
                   - result: å„ªåŒ–çµæœ
                   - metrics: ç›¸é—œæŒ‡æ¨™
            collection_name: é›†åˆåç¨±
        """
        if not self.initialize_embeddings():
            raise ValueError("Embeddings æœªåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ API Key")

        documents = []

        for case in cases:
            content = f"""
ã€å„ªåŒ–æ¡ˆä¾‹ã€‘
å•é¡Œï¼š{case.get('problem', 'æœªçŸ¥')}
è§£æ±ºæ–¹æ¡ˆï¼š{case.get('solution', 'æœªçŸ¥')}
çµæœï¼š{case.get('result', 'æœªçŸ¥')}

ã€æ”¹å–„æŒ‡æ¨™ã€‘
{json.dumps(case.get('metrics', {}), ensure_ascii=False, indent=2)}
"""

            metadata = {
                'type': 'optimization_case',
                'problem_type': case.get('problem_type', 'general'),
                'created_at': datetime.now().isoformat(),
                **case.get('metrics', {})
            }

            documents.append(Document(
                page_content=content,
                metadata=metadata
            ))

        print(f"ğŸ“š æ­£åœ¨å»ºç«‹å„ªåŒ–æ¡ˆä¾‹çŸ¥è­˜åº«ï¼š{len(documents)} ç­†æ¡ˆä¾‹...")

        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            collection_name=collection_name,
            persist_directory=self.persist_directory
        )

        print(f"âœ… å„ªåŒ–æ¡ˆä¾‹çŸ¥è­˜åº«å»ºç«‹å®Œæˆï¼")

    def get_stats(self) -> Dict[str, Any]:
        """
        ç²å–çŸ¥è­˜åº«çµ±è¨ˆè³‡è¨Š

        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        if not self.vectorstore:
            return {'status': 'not_loaded', 'count': 0}

        try:
            collection = self.vectorstore._collection
            count = collection.count()

            return {
                'status': 'loaded',
                'count': count,
                'persist_directory': self.persist_directory
            }
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ– RAG æœå‹™
    rag = RAGService()

    # ç¯„ä¾‹ï¼šå»ºç«‹çŸ¥è­˜åº«ï¼ˆéœ€è¦å¯¦éš›çš„ DataFrameï¼‰
    # rag.create_ad_creative_knowledge_base(df)

    # ç¯„ä¾‹ï¼šè¼‰å…¥çŸ¥è­˜åº«
    # rag.load_knowledge_base()

    # ç¯„ä¾‹ï¼šæœå°‹ç›¸ä¼¼å»£å‘Š
    # results = rag.search_similar_ads("é«˜è½‰æ›ç‡çš„ Headline", k=3)

    print("RAG Service æ¨¡çµ„è¼‰å…¥å®Œæˆ")
