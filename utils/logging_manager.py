"""
çµ±ä¸€æ—¥èªŒèˆ‡ç›£æ§ç³»çµ±ã€‚

- ä»¥ `logging` æ¨™æº–åº«é›†ä¸­ç®¡ç†å„æ¨¡çµ„è¼¸å‡ºçš„ç´€éŒ„ã€‚
- é è¨­è¼¸å‡ºè‡³ `logs/ai_agents.log`ï¼Œäº¦å¯é€éç’°å¢ƒè®Šæ•¸èª¿æ•´è·¯å¾‘èˆ‡ç­‰ç´šã€‚
- æä¾›ä¾¿æ·å‡½å¼è¨˜éŒ„äº‹ä»¶ã€æŒ‡æ¨™èˆ‡ä¾‹å¤–ç‹€æ³ã€‚
- èˆ‡ Streamlit/CLI å…±ç”¨ï¼Œç¢ºä¿æœ¬åœ°èˆ‡éƒ¨ç½²ç’°å¢ƒä¸€è‡´ã€‚
"""

from __future__ import annotations

import json
import logging
import os
from datetime import datetime
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Any, Dict, Optional

import streamlit as st

DEFAULT_LOG_FILE = os.getenv("AGENT_LOG_FILE", "logs/ai_agents.log")
DEFAULT_LOG_LEVEL = os.getenv("AGENT_LOG_LEVEL", "INFO").upper()
DEFAULT_MAX_BYTES = int(os.getenv("AGENT_LOG_MAX_BYTES", 5 * 1024 * 1024))
DEFAULT_BACKUP_COUNT = int(os.getenv("AGENT_LOG_BACKUP_COUNT", 3))

_LOGGER_CACHE: Dict[str, logging.Logger] = {}


def _ensure_log_directory(path: str) -> None:
    """ç¢ºä¿æ—¥èªŒç›®éŒ„å­˜åœ¨ã€‚"""
    log_path = Path(path).expanduser()
    log_path.parent.mkdir(parents=True, exist_ok=True)


def get_logger(name: str = "meta_ads") -> logging.Logger:
    """å–å¾—æˆ–å»ºç«‹æŒ‡å®šåç¨±çš„ loggerã€‚"""
    if name in _LOGGER_CACHE:
        return _LOGGER_CACHE[name]

    _ensure_log_directory(DEFAULT_LOG_FILE)

    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, DEFAULT_LOG_LEVEL, logging.INFO))

    if not logger.handlers:
        formatter = logging.Formatter(
            fmt="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        # æ—‹è½‰æª”æ¡ˆ handler
        file_handler = RotatingFileHandler(
            DEFAULT_LOG_FILE,
            maxBytes=DEFAULT_MAX_BYTES,
            backupCount=DEFAULT_BACKUP_COUNT,
            encoding="utf-8",
        )
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

        # Streamlit / CLI console handler
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)

    _LOGGER_CACHE[name] = logger
    return logger


def log_event(event: str, details: Optional[Dict[str, Any]] = None, level: int = logging.INFO) -> None:
    """
    è¨˜éŒ„ä¸€èˆ¬äº‹ä»¶ã€‚

    Args:
        event: äº‹ä»¶åç¨±
        details: äº‹ä»¶è£œå……è³‡è¨Š
        level: logging ç­‰ç´š
    """
    logger = get_logger()
    payload = {"event": event, **(details or {})}
    logger.log(level, json.dumps(payload, ensure_ascii=False))

    # æä¾›çµ¦ Streamlit é¡¯ç¤ºï¼ˆé¸æ“‡æ€§ï¼‰
    if os.getenv("AGENT_LOG_TO_STREAMLIT", "false").lower() == "true":
        st.caption(f"ğŸ“‹ æ—¥èªŒï¼š{event} - {payload}")


def log_exception(error: Exception, context: Optional[str] = None) -> None:
    """è¨˜éŒ„ä¾‹å¤–ç‹€æ³ä¸¦é™„ä¸Šå †ç–Šã€‚"""
    logger = get_logger()
    message = context or "Agent Exception"
    logger.exception("%s | %s", message, str(error))


def log_metric(name: str, value: Any, namespace: str = "agent") -> None:
    """è¨˜éŒ„æ•¸å€¼å‹æŒ‡æ¨™ï¼ˆæˆæœ¬ã€å»¶é²ç­‰ï¼‰ã€‚"""
    logger = get_logger()
    payload = {
        "metric": name,
        "namespace": namespace,
        "value": value,
        "timestamp": datetime.utcnow().isoformat(),
    }
    logger.info(json.dumps(payload, ensure_ascii=False))


__all__ = ["get_logger", "log_event", "log_exception", "log_metric"]
