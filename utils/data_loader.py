import os
from datetime import datetime
from pathlib import Path

import pandas as pd
import streamlit as st
from dotenv import load_dotenv


DEFAULT_DATA_FILE = "è€˜åˆèŒ¶é£Ÿ.xlsx"

# ç¢ºä¿åœ¨åŒ¯å…¥æ™‚å°±è¼‰å…¥ .env åƒæ•¸ï¼Œä¾¿æ–¼ CLI è…³æœ¬èˆ‡ Streamlit å…±ç”¨
load_dotenv()


def _resolve_data_path(file_path: str | None) -> Path:
    """æ ¹æ“šåƒæ•¸èˆ‡ç’°å¢ƒè®Šæ•¸å–å¾—å¯¦éš›è³‡æ–™è·¯å¾‘"""
    candidate = file_path or os.getenv("DATA_FILE_PATH") or DEFAULT_DATA_FILE
    return Path(candidate).expanduser()


def _noop_cache(*args, **kwargs):
    def decorator(func):
        return func

    return decorator


cache_data = getattr(st, "cache_data", None) or _noop_cache


def _ui_call(method: str, *args, **kwargs):
    fn = getattr(st, method, None)
    if callable(fn):
        return fn(*args, **kwargs)
    return None


def _sidebar_call(method: str, *args, **kwargs):
    sidebar = getattr(st, "sidebar", None)
    fn = getattr(sidebar, method, None) if sidebar else None
    if callable(fn):
        return fn(*args, **kwargs)
    return None


@cache_data(show_spinner=False)
def _load_and_preprocess_data(resolved_path: str) -> pd.DataFrame:
    """è¼‰å…¥ Excel ä¸¦å¥—ç”¨é è™•ç†ï¼ˆä¾› Streamlit å¿«å–ä½¿ç”¨ï¼‰"""
    df = pd.read_excel(resolved_path)
    return preprocess_data(df)


def load_meta_ads_data(
    file_path: str | None = None,
    show_sidebar_info: bool = True,
    sync_creative_store: bool = False,
) -> pd.DataFrame | None:
    """è¼‰å…¥ä¸¦é è™•ç† Meta å»£å‘Šæ•¸æ“šï¼Œä¾›å„é é¢å…±ç”¨

    Args:
        file_path: æŒ‡å®šè³‡æ–™è·¯å¾‘ï¼Œæœªæä¾›å‰‡ä¾åºå–ç’°å¢ƒè®Šæ•¸èˆ‡é è¨­æª”å
        show_sidebar_info: æ˜¯å¦æ–¼å´æ¬„é¡¯ç¤ºè³‡æ–™ä¾†æºèˆ‡ç­†æ•¸

    Returns:
        é è™•ç†å¾Œçš„æ•¸æ“šæ¡†æ¶ï¼Œè‹¥è¼‰å…¥å¤±æ•—å‰‡å›å‚³ None
    """
    resolved_path = _resolve_data_path(file_path)

    try:
        df = _load_and_preprocess_data(str(resolved_path))
    except FileNotFoundError:
        _ui_call("error", f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{resolved_path}")
        return None
    except Exception as exc:
        _ui_call("error", f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼š{exc}")
        return None

    if show_sidebar_info:
        _sidebar_call("success", f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼š{len(df)} ç­†è¨˜éŒ„")
        display_path = resolved_path.resolve().as_posix() if resolved_path.exists() else resolved_path.as_posix()
        _sidebar_call("caption", f"ğŸ“‚ æ•¸æ“šä¾†æºï¼š{display_path}")

    if sync_creative_store:
        try:
            from utils import creative_store

            creative_store.sync_from_meta_ads(df)
        except Exception as exc:
            _ui_call("warning", f"âš ï¸ ç´ ææˆæ•ˆè³‡æ–™åŒæ­¥å¤±æ•—ï¼š{exc}")

    return df

def preprocess_data(df):
    """
    æ•¸æ“šé è™•ç†

    Args:
        df (pd.DataFrame): åŸå§‹æ•¸æ“šæ¡†æ¶

    Returns:
        pd.DataFrame: è™•ç†å¾Œçš„æ•¸æ“šæ¡†æ¶
    """
    # è™•ç†æ—¥æœŸæ¬„ä½
    date_columns = ['é–‹å§‹', 'çµæŸæ™‚é–“', 'åˆ†æå ±å‘Šé–‹å§‹', 'åˆ†æå ±å‘ŠçµæŸ']
    for col in date_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce')

    # å¾æœˆä»½æ¬„ä½æå–å¹´æœˆ
    if 'æœˆ' in df.columns:
        df['æœˆä»½'] = pd.to_datetime(df['æœˆ'], errors='coerce')
        df['å¹´æœˆ'] = df['æœˆä»½'].dt.to_period('M').astype(str)

    # è¨ˆç®—æŠ•æ”¾å¤©æ•¸
    if 'é–‹å§‹' in df.columns and 'çµæŸæ™‚é–“' in df.columns:
        df['æŠ•æ”¾å¤©æ•¸'] = (df['çµæŸæ™‚é–“'] - df['é–‹å§‹']).dt.days + 1
        df['æŠ•æ”¾å¤©æ•¸'] = df['æŠ•æ”¾å¤©æ•¸'].fillna(1)  # é è¨­è‡³å°‘1å¤©

    # è¨ˆç®—æ—¥å‡èŠ±è²»
    if 'èŠ±è²»é‡‘é¡ (TWD)' in df.columns and 'æŠ•æ”¾å¤©æ•¸' in df.columns:
        df['æ—¥å‡èŠ±è²»'] = df['èŠ±è²»é‡‘é¡ (TWD)'] / df['æŠ•æ”¾å¤©æ•¸']

    # è™•ç†é ç®—æ¬„ä½ï¼ˆè½‰ç‚ºæ•¸å€¼ï¼‰
    budget_columns = ['å»£å‘Šçµ„åˆé ç®—', 'è¡ŒéŠ·æ´»å‹•é ç®—', 'æ—¥é ç®—']
    for col in budget_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # è¨ˆç®—è½‰æ›æ¼æ–—æŒ‡æ¨™
    df = calculate_funnel_metrics(df)

    # è™•ç†å“è³ªæ’åï¼ˆè½‰ç‚ºæ•¸å€¼ï¼‰
    df = process_quality_rankings(df)

    # å¡«å……æ•¸å€¼å‹æ¬„ä½çš„ç¼ºå¤±å€¼
    numeric_columns = df.select_dtypes(include=['number']).columns
    df[numeric_columns] = df[numeric_columns].fillna(0)

    # å¡«å……æ–‡å­—å‹æ¬„ä½çš„ç¼ºå¤±å€¼
    text_columns = df.select_dtypes(include=['object']).columns
    df[text_columns] = df[text_columns].fillna('æœªçŸ¥')

    return df

def calculate_funnel_metrics(df):
    """
    è¨ˆç®—è½‰æ›æ¼æ–—å„éšæ®µæŒ‡æ¨™

    Args:
        df (pd.DataFrame): æ•¸æ“šæ¡†æ¶

    Returns:
        pd.DataFrame: æ–°å¢æ¼æ–—æŒ‡æ¨™çš„æ•¸æ“šæ¡†æ¶
    """
    # é»æ“Šç‡
    if 'é€£çµé»æ“Šæ¬¡æ•¸' in df.columns and 'æ›å…‰æ¬¡æ•¸' in df.columns:
        df['é»æ“Šç‡'] = (df['é€£çµé»æ“Šæ¬¡æ•¸'] / df['æ›å…‰æ¬¡æ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    # é é¢ç€è¦½ç‡
    if 'é€£çµé é¢ç€è¦½æ¬¡æ•¸' in df.columns and 'é€£çµé»æ“Šæ¬¡æ•¸' in df.columns:
        df['é é¢ç€è¦½ç‡'] = (df['é€£çµé é¢ç€è¦½æ¬¡æ•¸'] / df['é€£çµé»æ“Šæ¬¡æ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    # å…§å®¹ç€è¦½ç‡
    if 'å…§å®¹ç€è¦½æ¬¡æ•¸' in df.columns and 'é€£çµé é¢ç€è¦½æ¬¡æ•¸' in df.columns:
        df['å…§å®¹ç€è¦½ç‡'] = (df['å…§å®¹ç€è¦½æ¬¡æ•¸'] / df['é€£çµé é¢ç€è¦½æ¬¡æ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    # åŠ è³¼ç‡
    if 'åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸' in df.columns and 'å…§å®¹ç€è¦½æ¬¡æ•¸' in df.columns:
        df['åŠ è³¼ç‡'] = (df['åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸'] / df['å…§å®¹ç€è¦½æ¬¡æ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    # çµå¸³ç‡
    if 'é–‹å§‹çµå¸³æ¬¡æ•¸' in df.columns and 'åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸' in df.columns:
        df['çµå¸³ç‡'] = (df['é–‹å§‹çµå¸³æ¬¡æ•¸'] / df['åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    # è³¼è²·å®Œæˆç‡
    if 'è³¼è²·æ¬¡æ•¸' in df.columns and 'é–‹å§‹çµå¸³æ¬¡æ•¸' in df.columns:
        df['è³¼è²·å®Œæˆç‡'] = (df['è³¼è²·æ¬¡æ•¸'] / df['é–‹å§‹çµå¸³æ¬¡æ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    # æ•´é«”è½‰æ›ç‡ï¼ˆå¾è§¸åŠåˆ°è³¼è²·ï¼‰
    if 'è³¼è²·æ¬¡æ•¸' in df.columns and 'è§¸åŠäººæ•¸' in df.columns:
        df['æ•´é«”è½‰æ›ç‡'] = (df['è³¼è²·æ¬¡æ•¸'] / df['è§¸åŠäººæ•¸'] * 100).replace([float('inf'), -float('inf')], 0)

    return df

def process_quality_rankings(df):
    """
    è™•ç†å“è³ªæ’åæ¬„ä½ï¼Œè½‰æ›ç‚ºæ•¸å€¼åˆ†æ•¸

    Args:
        df (pd.DataFrame): æ•¸æ“šæ¡†æ¶

    Returns:
        pd.DataFrame: è™•ç†å¾Œçš„æ•¸æ“šæ¡†æ¶
    """
    ranking_map = {
        'å¹³å‡ä»¥ä¸Š': 3,
        'Above Average': 3,
        'å¹³å‡': 2,
        'Average': 2,
        'å¹³å‡ä»¥ä¸‹': 1,
        'Below Average': 1,
        'æœªçŸ¥': 0,
        '-': 0,  # è™•ç†ç ´æŠ˜è™Ÿ
        '': 0
    }

    ranking_columns = ['å“è³ªæ’å', 'äº’å‹•ç‡æ’å', 'è½‰æ›ç‡æ’å']

    for col in ranking_columns:
        if col in df.columns:
            # å…ˆå°‡ NaN è½‰ç‚ºå­—ä¸²ï¼Œå†è™•ç†ç ´æŠ˜è™Ÿ
            df[col] = df[col].fillna('-')
            # å‰µå»ºæ•¸å€¼ç‰ˆæœ¬
            df[f'{col}_åˆ†æ•¸'] = df[col].map(ranking_map).fillna(0)
            # å°‡ç ´æŠ˜è™Ÿçµ±ä¸€ç‚ºã€ŒæœªçŸ¥ã€ä»¥ä¾¿åœ–è¡¨é¡¯ç¤º
            df[col] = df[col].replace('-', 'æœªçŸ¥')

    # è¨ˆç®—ç¶œåˆå“è³ªåˆ†æ•¸ï¼ˆè½‰æ›ç‡æ¬Šé‡æœ€é«˜ï¼‰
    if all(f'{col}_åˆ†æ•¸' in df.columns for col in ranking_columns):
        df['ç¶œåˆå“è³ªåˆ†æ•¸'] = (
            df['å“è³ªæ’å_åˆ†æ•¸'] * 0.25 +
            df['äº’å‹•ç‡æ’å_åˆ†æ•¸'] * 0.25 +
            df['è½‰æ›ç‡æ’å_åˆ†æ•¸'] * 0.5
        )

    return df

def calculate_summary_metrics(df):
    """
    è¨ˆç®—æ‘˜è¦æŒ‡æ¨™

    Args:
        df (pd.DataFrame): æ•¸æ“šæ¡†æ¶

    Returns:
        dict: æ‘˜è¦æŒ‡æ¨™å­—å…¸
    """
    if df is None or df.empty:
        return {}

    # åŸºæœ¬æˆæ•ˆæŒ‡æ¨™
    metrics = {
        'total_spend': df['èŠ±è²»é‡‘é¡ (TWD)'].sum(),
        'total_reach': df['è§¸åŠäººæ•¸'].sum(),
        'total_impressions': df['æ›å…‰æ¬¡æ•¸'].sum(),
        'total_clicks': df['é€£çµé»æ“Šæ¬¡æ•¸'].sum() if 'é€£çµé»æ“Šæ¬¡æ•¸' in df.columns else 0,
        'total_page_views': df['é€£çµé é¢ç€è¦½æ¬¡æ•¸'].sum() if 'é€£çµé é¢ç€è¦½æ¬¡æ•¸' in df.columns else 0,
        'total_content_views': df['å…§å®¹ç€è¦½æ¬¡æ•¸'].sum() if 'å…§å®¹ç€è¦½æ¬¡æ•¸' in df.columns else 0,
        'total_add_to_cart': df['åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸'].sum() if 'åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸' in df.columns else 0,
        'total_checkout': df['é–‹å§‹çµå¸³æ¬¡æ•¸'].sum() if 'é–‹å§‹çµå¸³æ¬¡æ•¸' in df.columns else 0,
        'total_purchases': df['è³¼è²·æ¬¡æ•¸'].sum() if 'è³¼è²·æ¬¡æ•¸' in df.columns else 0,

        # å¹³å‡æŒ‡æ¨™
        'avg_frequency': df['é »ç‡'].mean() if 'é »ç‡' in df.columns else 0,
        'avg_ctr': df['CTRï¼ˆå…¨éƒ¨ï¼‰'].mean() if 'CTRï¼ˆå…¨éƒ¨ï¼‰' in df.columns else 0,
        'avg_cpm': df['CPMï¼ˆæ¯åƒæ¬¡å»£å‘Šæ›å…‰æˆæœ¬ï¼‰'].mean() if 'CPMï¼ˆæ¯åƒæ¬¡å»£å‘Šæ›å…‰æˆæœ¬ï¼‰' in df.columns else 0,
        'avg_cpc': df['CPCï¼ˆå–®æ¬¡é€£çµé»æ“Šæˆæœ¬ï¼‰'].mean() if 'CPCï¼ˆå–®æ¬¡é€£çµé»æ“Šæˆæœ¬ï¼‰' in df.columns else 0,
        'avg_cpa': df['æ¯æ¬¡è³¼è²·çš„æˆæœ¬'].mean() if 'æ¯æ¬¡è³¼è²·çš„æˆæœ¬' in df.columns else 0,
        'avg_roas': df['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'].mean() if 'è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰' in df.columns else 0,

        # è½‰æ›ç‡æŒ‡æ¨™
        'click_rate': (df['é€£çµé»æ“Šæ¬¡æ•¸'].sum() / df['æ›å…‰æ¬¡æ•¸'].sum() * 100) if df['æ›å…‰æ¬¡æ•¸'].sum() > 0 else 0,
        'page_view_rate': (df['é€£çµé é¢ç€è¦½æ¬¡æ•¸'].sum() / df['é€£çµé»æ“Šæ¬¡æ•¸'].sum() * 100) if df['é€£çµé»æ“Šæ¬¡æ•¸'].sum() > 0 and 'é€£çµé é¢ç€è¦½æ¬¡æ•¸' in df.columns else 0,
        'add_to_cart_rate': (df['åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸'].sum() / df['å…§å®¹ç€è¦½æ¬¡æ•¸'].sum() * 100) if df['å…§å®¹ç€è¦½æ¬¡æ•¸'].sum() > 0 and 'åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸' in df.columns else 0,
        'checkout_rate': (df['é–‹å§‹çµå¸³æ¬¡æ•¸'].sum() / df['åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸'].sum() * 100) if df['åŠ åˆ°è³¼ç‰©è»Šæ¬¡æ•¸'].sum() > 0 and 'é–‹å§‹çµå¸³æ¬¡æ•¸' in df.columns else 0,
        'purchase_rate': (df['è³¼è²·æ¬¡æ•¸'].sum() / df['é–‹å§‹çµå¸³æ¬¡æ•¸'].sum() * 100) if df['é–‹å§‹çµå¸³æ¬¡æ•¸'].sum() > 0 and 'è³¼è²·æ¬¡æ•¸' in df.columns else 0,
        'overall_conversion_rate': (df['è³¼è²·æ¬¡æ•¸'].sum() / df['è§¸åŠäººæ•¸'].sum() * 100) if df['è§¸åŠäººæ•¸'].sum() > 0 and 'è³¼è²·æ¬¡æ•¸' in df.columns else 0,

        # å…¶ä»–è³‡è¨Š
        'total_records': len(df),
        'date_range': {
            'start': df['é–‹å§‹'].min() if 'é–‹å§‹' in df.columns and not df['é–‹å§‹'].isna().all() else None,
            'end': df['çµæŸæ™‚é–“'].max() if 'çµæŸæ™‚é–“' in df.columns and not df['çµæŸæ™‚é–“'].isna().all() else None
        }
    }

    return metrics

def get_campaign_status_counts(df):
    """
    ç²å–æ´»å‹•ç‹€æ…‹çµ±è¨ˆ

    Args:
        df (pd.DataFrame): æ•¸æ“šæ¡†æ¶

    Returns:
        dict: ç‹€æ…‹çµ±è¨ˆå­—å…¸
    """
    if df is None or df.empty:
        return {'good': 0, 'warning': 0, 'poor': 0}

    # æ ¹æ“š ROAS åˆ†é¡æ´»å‹•è¡¨ç¾
    good_campaigns = len(df[df['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] >= 3.0])
    warning_campaigns = len(df[(df['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] >= 1.0) &
                                (df['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] < 3.0)])
    poor_campaigns = len(df[df['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] < 1.0])

    return {
        'good': good_campaigns,
        'warning': warning_campaigns,
        'poor': poor_campaigns
    }

def filter_data_by_date_range(df, start_date, end_date):
    """
    æ ¹æ“šæ—¥æœŸç¯„åœç¯©é¸æ•¸æ“š

    Args:
        df (pd.DataFrame): æ•¸æ“šæ¡†æ¶
        start_date (datetime): é–‹å§‹æ—¥æœŸ
        end_date (datetime): çµæŸæ—¥æœŸ

    Returns:
        pd.DataFrame: ç¯©é¸å¾Œçš„æ•¸æ“šæ¡†æ¶
    """
    if df is None or df.empty:
        return df

    # å„ªå…ˆä½¿ç”¨å»£å‘ŠæŠ•æ”¾æ—¥æœŸ('é–‹å§‹')é€²è¡Œç¯©é¸
    if 'é–‹å§‹' in df.columns:
        date_column = 'é–‹å§‹'

        # å…ˆç§»é™¤æ—¥æœŸç‚ºç©ºçš„è¨˜éŒ„
        df_with_dates = df.dropna(subset=[date_column])

        if df_with_dates.empty:
            _ui_call("warning", "âš ï¸ æ‰€æœ‰è¨˜éŒ„çš„å»£å‘Šé–‹å§‹æ—¥æœŸéƒ½ç‚ºç©º")
            return pd.DataFrame()

        # ä½¿ç”¨å»£å‘ŠæŠ•æ”¾æ—¥æœŸé€²è¡Œç¯©é¸
        mask = (df_with_dates[date_column] >= pd.Timestamp(start_date)) & (df_with_dates[date_column] <= pd.Timestamp(end_date))
        filtered_df = df_with_dates[mask]

        if filtered_df.empty:
            _ui_call(
                "warning",
                f"âš ï¸ åœ¨ {start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')} æœŸé–“æ²’æœ‰å»£å‘ŠæŠ•æ”¾æ•¸æ“š",
            )
        else:
            _ui_call(
                "info",
                f"ğŸ“… å·²ç¯©é¸å»£å‘ŠæŠ•æ”¾æœŸé–“ {start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')} çš„æ•¸æ“šï¼Œå…± {len(filtered_df)} ç­†è¨˜éŒ„",
            )

        return filtered_df

    # å‚™ç”¨ï¼šå¦‚æœæ²’æœ‰é–‹å§‹æ—¥æœŸï¼Œå˜—è©¦ä½¿ç”¨åˆ†æå ±å‘Šæ—¥æœŸ
    elif 'åˆ†æå ±å‘Šé–‹å§‹' in df.columns:
        # å…ˆç§»é™¤æ—¥æœŸç‚ºç©ºçš„è¨˜éŒ„
        df_with_dates = df.dropna(subset=['åˆ†æå ±å‘Šé–‹å§‹'])

        if df_with_dates.empty:
            _ui_call("warning", "âš ï¸ æ‰€æœ‰è¨˜éŒ„çš„åˆ†æå ±å‘Šæ—¥æœŸéƒ½ç‚ºç©º")
            return pd.DataFrame()

        # æª¢æŸ¥ç¯©é¸ç¯„åœæ˜¯å¦èˆ‡åˆ†æå ±å‘ŠæœŸé–“é‡ç–Š
        report_start = df_with_dates['åˆ†æå ±å‘Šé–‹å§‹'].iloc[0].date()
        report_end = df_with_dates['åˆ†æå ±å‘ŠçµæŸ'].iloc[0].date() if 'åˆ†æå ±å‘ŠçµæŸ' in df_with_dates.columns else report_start

        # å¦‚æœé¸æ“‡çš„ç¯„åœèˆ‡å ±å‘ŠæœŸé–“æœ‰é‡ç–Šï¼Œè¿”å›æ‰€æœ‰æ•¸æ“š
        if start_date <= report_end and end_date >= report_start:
            filtered_df = df_with_dates
            _ui_call(
                "info",
                f"ğŸ“… åˆ†æå ±å‘ŠæœŸé–“ ({report_start} è‡³ {report_end}) èˆ‡é¸æ“‡ç¯„åœé‡ç–Šï¼Œé¡¯ç¤ºæ‰€æœ‰ {len(filtered_df)} ç­†è¨˜éŒ„",
            )
        else:
            filtered_df = pd.DataFrame()
            _ui_call(
                "warning",
                f"âš ï¸ é¸æ“‡çš„æ™‚é–“ç¯„åœèˆ‡åˆ†æå ±å‘ŠæœŸé–“ ({report_start} è‡³ {report_end}) ä¸é‡ç–Š",
            )

        return filtered_df

    else:
        _ui_call("warning", "âš ï¸ æ•¸æ“šä¸­ç¼ºå°‘æ—¥æœŸæ¬„ä½ï¼Œç„¡æ³•é€²è¡Œæ—¥æœŸç¯©é¸")
        return df

def export_data_to_csv(df, filename_prefix="meta_ads_export"):
    """
    åŒ¯å‡ºæ•¸æ“šç‚º CSV æ ¼å¼

    Args:
        df (pd.DataFrame): è¦åŒ¯å‡ºçš„æ•¸æ“šæ¡†æ¶
        filename_prefix (str): æª”æ¡ˆåå‰ç¶´

    Returns:
        str: CSV å­—ä¸²
    """
    if df is None or df.empty:
        return ""

    # ç”Ÿæˆæª”æ¡ˆå
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{filename_prefix}_{timestamp}.csv"

    # è½‰æ›ç‚º CSV
    csv_string = df.to_csv(index=False, encoding='utf-8-sig')

    return csv_string, filename

def validate_data_quality(df):
    """
    æª¢æŸ¥æ•¸æ“šå“è³ª

    Args:
        df (pd.DataFrame): æ•¸æ“šæ¡†æ¶

    Returns:
        dict: æ•¸æ“šå“è³ªå ±å‘Š
    """
    if df is None or df.empty:
        return {"status": "error", "message": "æ•¸æ“šç‚ºç©º"}

    quality_report = {
        "status": "good",
        "total_records": len(df),
        "missing_data": {},
        "warnings": [],
        "errors": []
    }

    # æª¢æŸ¥é—œéµæ¬„ä½çš„ç¼ºå¤±æƒ…æ³
    key_columns = ['èŠ±è²»é‡‘é¡ (TWD)', 'è³¼è²·æ¬¡æ•¸', 'è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰', 'è§¸åŠäººæ•¸']

    for col in key_columns:
        if col in df.columns:
            missing_count = df[col].isna().sum()
            missing_percentage = (missing_count / len(df)) * 100

            quality_report["missing_data"][col] = {
                "count": missing_count,
                "percentage": missing_percentage
            }

            if missing_percentage > 50:
                quality_report["errors"].append(f"{col} ç¼ºå¤±ç‡éé«˜ï¼š{missing_percentage:.1f}%")
                quality_report["status"] = "error"
            elif missing_percentage > 20:
                quality_report["warnings"].append(f"{col} ç¼ºå¤±ç‡è¼ƒé«˜ï¼š{missing_percentage:.1f}%")
                if quality_report["status"] == "good":
                    quality_report["status"] = "warning"
        else:
            quality_report["errors"].append(f"ç¼ºå°‘é—œéµæ¬„ä½ï¼š{col}")
            quality_report["status"] = "error"

    return quality_report
