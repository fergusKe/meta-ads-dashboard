import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from utils.data_loader import load_meta_ads_data, filter_data_by_date_range
import numpy as np
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
import warnings
warnings.filterwarnings('ignore')

def show_trend_analysis():
    """é¡¯ç¤ºè¶¨å‹¢åˆ†æé é¢"""
    st.markdown("# ğŸ“ˆ è¶¨å‹¢åˆ†æ")
    st.markdown("æ·±å…¥åˆ†æå»£å‘ŠæŠ•æ”¾è¶¨å‹¢ï¼Œé æ¸¬æœªä¾†è¡¨ç¾ä¸¦è­˜åˆ¥é—œéµè®ŠåŒ–é»")

    # è¼‰å…¥æ•¸æ“š
    df = load_meta_ads_data()
    if df is None:
        st.error("ç„¡æ³•è¼‰å…¥æ•¸æ“šï¼Œè«‹æª¢æŸ¥æ•¸æ“šæª”æ¡ˆã€‚")
        return

    # æ™‚é–“ç¯„åœé¸æ“‡å™¨
    st.markdown("## ğŸ“… æ™‚é–“ç¯„åœè¨­å®š")

    col1, col2, col3 = st.columns([2, 2, 2])

    with col1:
        # å„ªå…ˆä½¿ç”¨åˆ†æå ±å‘Šæ—¥æœŸç¯„åœ
        if 'åˆ†æå ±å‘Šé–‹å§‹' in df.columns and 'åˆ†æå ±å‘ŠçµæŸ' in df.columns:
            report_start_dates = df['åˆ†æå ±å‘Šé–‹å§‹'].dropna()
            report_end_dates = df['åˆ†æå ±å‘ŠçµæŸ'].dropna()

            if not report_start_dates.empty and not report_end_dates.empty:
                report_start = report_start_dates.min()
                report_end = report_end_dates.max()

                # ç¯©é¸å»£å‘ŠæŠ•æ”¾æ—¥æœŸåœ¨åˆ†æå ±å‘ŠæœŸé–“å…§çš„æ•¸æ“š
                analysis_df = df[
                    (df['é–‹å§‹'] >= report_start) &
                    (df['é–‹å§‹'] <= report_end)
                ].copy()

                if not analysis_df.empty:
                    data_min_date = analysis_df['é–‹å§‹'].min().date()
                    data_max_date = analysis_df['é–‹å§‹'].max().date()
                    default_start = data_min_date
                    default_end = data_max_date
                    date_source = "åˆ†ææœŸé–“"
                else:
                    # å¦‚æœæ²’æœ‰ç¬¦åˆçš„æ•¸æ“šï¼Œä½¿ç”¨å ±å‘ŠæœŸé–“çš„æ—¥æœŸ
                    data_min_date = report_start.date()
                    data_max_date = report_end.date()
                    default_start = data_min_date
                    default_end = data_max_date
                    date_source = "åˆ†ææœŸé–“"
            else:
                data_min_date = datetime.now().date() - timedelta(days=30)
                data_max_date = datetime.now().date()
                default_start = data_min_date
                default_end = data_max_date
                date_source = "é è¨­"
        else:
            # å‚™ç”¨ï¼šä½¿ç”¨é–‹å§‹æ—¥æœŸ
            if 'é–‹å§‹' in df.columns and not df['é–‹å§‹'].isna().all():
                valid_dates = df['é–‹å§‹'].dropna()
                if not valid_dates.empty:
                    data_min_date = valid_dates.min().date()
                    data_max_date = valid_dates.max().date()
                    default_start = data_min_date
                    default_end = data_max_date
                    date_source = "å»£å‘Šé–‹å§‹"
                else:
                    data_min_date = datetime.now().date() - timedelta(days=30)
                    data_max_date = datetime.now().date()
                    default_start = data_min_date
                    default_end = data_max_date
                    date_source = "é è¨­"
            else:
                data_min_date = datetime.now().date() - timedelta(days=30)
                data_max_date = datetime.now().date()
                default_start = data_min_date
                default_end = data_max_date
                date_source = "é è¨­"

        start_date = st.date_input(
            "é–‹å§‹æ—¥æœŸ",
            value=default_start,
            min_value=data_min_date,
            max_value=data_max_date,
            help=f"å¯¦éš›æ•¸æ“šç¯„åœï¼š{data_min_date} è‡³ {data_max_date} (ä¾†æºï¼š{date_source})"
        )

    with col2:
        end_date = st.date_input(
            "çµæŸæ—¥æœŸ",
            value=default_end,
            min_value=data_min_date,
            max_value=data_max_date,
            help=f"å¯¦éš›æ•¸æ“šç¯„åœï¼š{data_min_date} è‡³ {data_max_date} (ä¾†æºï¼š{date_source})"
        )

    with col3:
        # å¿«é€Ÿé¸é …
        quick_options = st.selectbox(
            "å¿«é€Ÿé¸æ“‡",
            ["è‡ªè¨‚ç¯„åœ", "æœ€è¿‘ 7 å¤©", "æœ€è¿‘ 14 å¤©", "æœ€è¿‘ 30 å¤©", "å…¨éƒ¨æ™‚é–“"]
        )

        if quick_options != "è‡ªè¨‚ç¯„åœ":
            if quick_options == "æœ€è¿‘ 7 å¤©":
                start_date = max(data_max_date - timedelta(days=7), data_min_date)
                end_date = data_max_date
            elif quick_options == "æœ€è¿‘ 14 å¤©":
                start_date = max(data_max_date - timedelta(days=14), data_min_date)
                end_date = data_max_date
            elif quick_options == "æœ€è¿‘ 30 å¤©":
                start_date = max(data_max_date - timedelta(days=30), data_min_date)
                end_date = data_max_date
            elif quick_options == "å…¨éƒ¨æ™‚é–“":
                start_date = data_min_date
                end_date = data_max_date

    # ç¯©é¸æ•¸æ“š
    if start_date <= end_date:
        filtered_df = filter_data_by_date_range(df, start_date, end_date)
    else:
        st.error("é–‹å§‹æ—¥æœŸä¸èƒ½æ™šæ–¼çµæŸæ—¥æœŸï¼")
        filtered_df = df

    st.markdown("---")

    if not filtered_df.empty:
        # è¶¨å‹¢åˆ†æä¸»è¦å…§å®¹
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ æ ¸å¿ƒæŒ‡æ¨™è¶¨å‹¢", "ğŸ” æ·±åº¦åˆ†æ", "ğŸ¯ é æ¸¬æ¨¡å‹", "ğŸ“Š å‘¨æœŸæ€§åˆ†æ"])

        with tab1:
            st.markdown("### ğŸ“Š æ ¸å¿ƒæŒ‡æ¨™è¶¨å‹¢åˆ†æ")

            # æº–å‚™æ™‚é–“åºåˆ—æ•¸æ“š
            trend_data = prepare_time_series_data(filtered_df)

            if not trend_data.empty:
                # æŒ‡æ¨™é¸æ“‡
                metric_col1, metric_col2 = st.columns(2)

                with metric_col1:
                    primary_metric = st.selectbox(
                        "ä¸»è¦æŒ‡æ¨™",
                        ["èŠ±è²»é‡‘é¡ (TWD)", "è³¼è²·æ¬¡æ•¸", "è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰", "è§¸åŠäººæ•¸", "æ›å…‰æ¬¡æ•¸"],
                        index=0
                    )

                with metric_col2:
                    secondary_metric = st.selectbox(
                        "å°æ¯”æŒ‡æ¨™",
                        ["è³¼è²·æ¬¡æ•¸", "èŠ±è²»é‡‘é¡ (TWD)", "è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰", "è§¸åŠäººæ•¸", "æ›å…‰æ¬¡æ•¸"],
                        index=0
                    )

                # é›™è»¸è¶¨å‹¢åœ–
                fig_trend = create_dual_axis_trend_chart(trend_data, primary_metric, secondary_metric)
                if fig_trend:
                    st.plotly_chart(fig_trend, use_container_width=True)

                # è¶¨å‹¢çµ±è¨ˆæ‘˜è¦
                trend_summary_col1, trend_summary_col2, trend_summary_col3 = st.columns(3)

                with trend_summary_col1:
                    # è¨ˆç®—ä¸»è¦æŒ‡æ¨™çš„è¶¨å‹¢
                    trend_stats = calculate_trend_statistics(trend_data, primary_metric)
                    st.metric(
                        f"{primary_metric} è¶¨å‹¢",
                        f"{trend_stats['trend_direction']}",
                        delta=f"{trend_stats['change_rate']:.1f}%"
                    )

                with trend_summary_col2:
                    # æ³¢å‹•æ€§åˆ†æ
                    volatility = trend_data[primary_metric].std() / trend_data[primary_metric].mean() * 100 if trend_data[primary_metric].mean() > 0 else 0
                    volatility_status = "ä½" if volatility < 20 else "ä¸­" if volatility < 50 else "é«˜"
                    st.metric(
                        "æ³¢å‹•æ€§",
                        f"{volatility_status}",
                        delta=f"{volatility:.1f}%"
                    )

                with trend_summary_col3:
                    # ç›¸é—œæ€§åˆ†æ
                    if primary_metric != secondary_metric and len(trend_data) > 1:
                        correlation = trend_data[primary_metric].corr(trend_data[secondary_metric])
                        corr_strength = "å¼·" if abs(correlation) > 0.7 else "ä¸­" if abs(correlation) > 0.3 else "å¼±"
                        st.metric(
                            "æŒ‡æ¨™ç›¸é—œæ€§",
                            f"{corr_strength}",
                            delta=f"{correlation:.3f}"
                        )

                # æ¯æ—¥è¡¨ç¾åˆ†æ
                st.markdown("### ğŸ“… æ¯æ—¥è¡¨ç¾æ˜ç´°")
                daily_performance_chart = create_daily_performance_chart(trend_data)
                if daily_performance_chart:
                    st.plotly_chart(daily_performance_chart, use_container_width=True)

            else:
                st.info("æ‰€é¸æ™‚é–“ç¯„åœå…§æš«ç„¡è¶¨å‹¢æ•¸æ“š")

        with tab2:
            st.markdown("### ğŸ” æ·±åº¦è¶¨å‹¢åˆ†æ")

            if not trend_data.empty:
                analysis_col1, analysis_col2 = st.columns(2)

                with analysis_col1:
                    st.markdown("#### ğŸ“ˆ ç§»å‹•å¹³å‡åˆ†æ")

                    # ç§»å‹•å¹³å‡é¸é …
                    ma_period = st.selectbox("ç§»å‹•å¹³å‡å‘¨æœŸ", [3, 5, 7], index=1)
                    ma_metric = st.selectbox(
                        "åˆ†ææŒ‡æ¨™",
                        ["è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰", "èŠ±è²»é‡‘é¡ (TWD)", "è³¼è²·æ¬¡æ•¸", "è§¸åŠäººæ•¸"],
                        index=0
                    )

                    # ç§»å‹•å¹³å‡åœ–è¡¨
                    ma_chart = create_moving_average_chart(trend_data, ma_metric, ma_period)
                    if ma_chart:
                        st.plotly_chart(ma_chart, use_container_width=True)

                with analysis_col2:
                    st.markdown("#### ğŸ“Š ç•°å¸¸æª¢æ¸¬")

                    # ç•°å¸¸æª¢æ¸¬
                    anomalies = detect_anomalies(trend_data, ma_metric)

                    if anomalies and len(anomalies) > 0:
                        st.warning(f"âš ï¸ æª¢æ¸¬åˆ° {len(anomalies)} å€‹ç•°å¸¸æ•¸æ“šé»")

                        # é¡¯ç¤ºç•°å¸¸è©³æƒ…
                        for i, anomaly in enumerate(anomalies[:3]):  # åªé¡¯ç¤ºå‰3å€‹
                            date_str = anomaly['date'].strftime('%Y-%m-%d')
                            st.error(f"**{date_str}**: {ma_metric} = {anomaly['value']:.2f} (åå·®: {anomaly['deviation']:.1f}Ïƒ)")
                    else:
                        st.success("âœ… æœªæª¢æ¸¬åˆ°é¡¯è‘—ç•°å¸¸")

                # è®ŠåŒ–é»æª¢æ¸¬
                st.markdown("#### ğŸ¯ è¶¨å‹¢è®ŠåŒ–é»åˆ†æ")
                change_points = detect_change_points(trend_data, ma_metric)

                if change_points:
                    change_col1, change_col2 = st.columns(2)

                    with change_col1:
                        st.info(f"ğŸ” æª¢æ¸¬åˆ° {len(change_points)} å€‹è¶¨å‹¢è®ŠåŒ–é»")
                        for i, cp in enumerate(change_points[:3]):
                            date_str = cp['date'].strftime('%Y-%m-%d')
                            change_type = "ä¸Šå‡" if cp['change'] > 0 else "ä¸‹é™"
                            st.write(f"**{date_str}**: {change_type} ({cp['change']:+.1f}%)")

                    with change_col2:
                        # è®ŠåŒ–é»åœ–è¡¨
                        change_chart = create_change_point_chart(trend_data, ma_metric, change_points)
                        if change_chart:
                            st.plotly_chart(change_chart, use_container_width=True)
                else:
                    st.info("ğŸ” æœªæª¢æ¸¬åˆ°é¡¯è‘—çš„è¶¨å‹¢è®ŠåŒ–é»")

            else:
                st.info("æ‰€é¸æ™‚é–“ç¯„åœå…§æš«ç„¡æ·±åº¦åˆ†ææ•¸æ“š")

        with tab3:
            st.markdown("### ğŸ¯ è¶¨å‹¢é æ¸¬æ¨¡å‹")

            if not trend_data.empty and len(trend_data) >= 5:
                predict_col1, predict_col2 = st.columns(2)

                with predict_col1:
                    predict_metric = st.selectbox(
                        "é æ¸¬æŒ‡æ¨™",
                        ["è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰", "èŠ±è²»é‡‘é¡ (TWD)", "è³¼è²·æ¬¡æ•¸"],
                        index=0,
                        key="predict_metric"
                    )

                    predict_days = st.slider("é æ¸¬å¤©æ•¸", 1, 14, 7)

                with predict_col2:
                    prediction_model = st.selectbox(
                        "é æ¸¬æ¨¡å‹",
                        ["ç·šæ€§è¿´æ­¸", "å¤šé …å¼è¿´æ­¸", "ç§»å‹•å¹³å‡"],
                        index=0
                    )

                # ç”Ÿæˆé æ¸¬
                predictions = generate_predictions(trend_data, predict_metric, predict_days, prediction_model)

                if predictions is not None:
                    # é æ¸¬åœ–è¡¨
                    prediction_chart = create_prediction_chart(trend_data, predictions, predict_metric)
                    if prediction_chart:
                        st.plotly_chart(prediction_chart, use_container_width=True)

                    # é æ¸¬æ‘˜è¦
                    pred_summary_col1, pred_summary_col2, pred_summary_col3 = st.columns(3)

                    current_value = trend_data[predict_metric].iloc[-1]
                    predicted_value = predictions['predicted_values'].iloc[-1]
                    change_percent = ((predicted_value - current_value) / current_value * 100) if current_value != 0 else 0

                    with pred_summary_col1:
                        st.metric(
                            "ç•¶å‰å€¼",
                            f"{current_value:.2f}",
                            help=f"æœ€æ–°çš„ {predict_metric} æ•¸å€¼"
                        )

                    with pred_summary_col2:
                        st.metric(
                            f"{predict_days}å¤©å¾Œé æ¸¬å€¼",
                            f"{predicted_value:.2f}",
                            delta=f"{change_percent:+.1f}%"
                        )

                    with pred_summary_col3:
                        # é æ¸¬å¯ä¿¡åº¦
                        confidence = calculate_prediction_confidence(trend_data, predict_metric, prediction_model)
                        confidence_level = "é«˜" if confidence > 0.8 else "ä¸­" if confidence > 0.5 else "ä½"
                        st.metric(
                            "é æ¸¬å¯ä¿¡åº¦",
                            confidence_level,
                            delta=f"{confidence:.2f}"
                        )

                    # é æ¸¬å»ºè­°
                    st.markdown("#### ğŸ’¡ é æ¸¬åˆ†æå»ºè­°")
                    if change_percent > 10:
                        st.success(f"ğŸ“ˆ é æ¸¬ {predict_metric} å°‡é¡¯è‘—ä¸Šå‡ ({change_percent:+.1f}%)ï¼Œå»ºè­°ä¿æŒç•¶å‰ç­–ç•¥æˆ–æ“´å¤§æŠ•è³‡")
                    elif change_percent < -10:
                        st.warning(f"ğŸ“‰ é æ¸¬ {predict_metric} å°‡é¡¯è‘—ä¸‹é™ ({change_percent:+.1f}%)ï¼Œå»ºè­°æª¢è¦–ä¸¦èª¿æ•´ç­–ç•¥")
                    else:
                        st.info(f"ğŸ“Š é æ¸¬ {predict_metric} ä¿æŒç©©å®š ({change_percent:+.1f}%)ï¼Œç¶­æŒç¾ç‹€å³å¯")

                else:
                    st.error("é æ¸¬æ¨¡å‹è¨ˆç®—å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§")

            else:
                st.info("éœ€è¦è‡³å°‘5å€‹æ•¸æ“šé»æ‰èƒ½é€²è¡Œè¶¨å‹¢é æ¸¬")

        with tab4:
            st.markdown("### ğŸ“Š å‘¨æœŸæ€§èˆ‡å­£ç¯€æ€§åˆ†æ")

            if not trend_data.empty:
                # æ˜ŸæœŸå¹¾åˆ†æ
                weekly_analysis = analyze_weekly_patterns(trend_data)

                if not weekly_analysis.empty:
                    week_col1, week_col2 = st.columns(2)

                    with week_col1:
                        st.markdown("#### ğŸ“… æ˜ŸæœŸå¹¾è¡¨ç¾åˆ†æ")
                        weekly_chart = create_weekly_pattern_chart(weekly_analysis)
                        if weekly_chart:
                            st.plotly_chart(weekly_chart, use_container_width=True)

                    with week_col2:
                        st.markdown("#### ğŸ† æœ€ä½³è¡¨ç¾æ—¥")

                        # æ‰¾å‡ºè¡¨ç¾æœ€å¥½å’Œæœ€å·®çš„æ˜ŸæœŸå¹¾
                        best_day = weekly_analysis.loc[weekly_analysis['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'].idxmax()]
                        worst_day = weekly_analysis.loc[weekly_analysis['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'].idxmin()]

                        st.success(f"ğŸ¥‡ **æœ€ä½³**: {best_day['weekday']} (ROAS: {best_day['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰']:.2f})")
                        st.error(f"ğŸ“‰ **æœ€å·®**: {worst_day['weekday']} (ROAS: {worst_day['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰']:.2f})")

                        # è¨ˆç®—å·®ç•°
                        performance_gap = ((best_day['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] - worst_day['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰']) / worst_day['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'] * 100)
                        st.info(f"ğŸ“Š **è¡¨ç¾å·®è·**: {performance_gap:.1f}%")

                # æ™‚æ®µåˆ†æï¼ˆå¦‚æœæœ‰å°æ™‚æ•¸æ“šï¼‰
                if 'é–‹å§‹' in trend_data.columns:
                    st.markdown("#### â° æŠ•æ”¾æ™‚é–“åˆ†æ")
                    time_analysis = analyze_time_patterns(trend_data)

                    if time_analysis:
                        time_col1, time_col2 = st.columns(2)

                        with time_col1:
                            # æŠ•æ”¾æ™‚é–“åˆ†ä½ˆ
                            hour_dist_chart = create_hour_distribution_chart(trend_data)
                            if hour_dist_chart:
                                st.plotly_chart(hour_dist_chart, use_container_width=True)

                        with time_col2:
                            # æ™‚æ®µå»ºè­°
                            st.markdown("##### ğŸ¯ æŠ•æ”¾æ™‚æ®µå»ºè­°")
                            optimal_hours = time_analysis['optimal_hours']
                            if optimal_hours:
                                st.success(f"ğŸŒŸ **æœ€ä½³æ™‚æ®µ**: {optimal_hours[0]}:00 - {optimal_hours[-1]}:00")
                                st.info(f"ğŸ“ˆ å»ºè­°åœ¨é€™äº›æ™‚æ®µå¢åŠ é ç®—æŠ•æ”¾")
                            else:
                                st.info("æ•¸æ“šä¸è¶³ä»¥ç¢ºå®šæœ€ä½³æŠ•æ”¾æ™‚æ®µ")

            else:
                st.info("æ‰€é¸æ™‚é–“ç¯„åœå…§æš«ç„¡å‘¨æœŸæ€§åˆ†ææ•¸æ“š")

    else:
        st.info("æ‰€é¸æ™‚é–“ç¯„åœå…§æš«ç„¡æ•¸æ“š")

def prepare_time_series_data(df):
    """æº–å‚™æ™‚é–“åºåˆ—æ•¸æ“š"""
    if df is None or df.empty or 'é–‹å§‹' not in df.columns:
        return pd.DataFrame()

    # é¦–å…ˆæ‡‰ç”¨èˆ‡å…¶ä»–é é¢ç›¸åŒçš„æ—¥æœŸç¯©é¸é‚è¼¯
    filtered_df = df.copy()

    # å„ªå…ˆä½¿ç”¨åˆ†æå ±å‘ŠæœŸé–“ç¯©é¸
    if 'åˆ†æå ±å‘Šé–‹å§‹' in df.columns and 'åˆ†æå ±å‘ŠçµæŸ' in df.columns:
        report_start_dates = df['åˆ†æå ±å‘Šé–‹å§‹'].dropna()
        report_end_dates = df['åˆ†æå ±å‘ŠçµæŸ'].dropna()

        if not report_start_dates.empty and not report_end_dates.empty:
            report_start = report_start_dates.min()
            report_end = report_end_dates.max()

            # ç¯©é¸å»£å‘ŠæŠ•æ”¾æ—¥æœŸåœ¨åˆ†æå ±å‘ŠæœŸé–“å…§çš„æ•¸æ“š
            filtered_df = df[
                (df['é–‹å§‹'] >= report_start) &
                (df['é–‹å§‹'] <= report_end)
            ].copy()

    # éæ¿¾æœ‰æ•ˆæ•¸æ“š
    valid_data = filtered_df.dropna(subset=['é–‹å§‹'])

    if valid_data.empty:
        return pd.DataFrame()

    # æŒ‰æ—¥æœŸåˆ†çµ„èšåˆ
    daily_data = valid_data.groupby(valid_data['é–‹å§‹'].dt.date).agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum',
        'è³¼è²·æ¬¡æ•¸': 'sum',
        'è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰': 'mean',
        'è§¸åŠäººæ•¸': 'sum',
        'æ›å…‰æ¬¡æ•¸': 'sum',
        'CTRï¼ˆå…¨éƒ¨ï¼‰': 'mean',
        'CPMï¼ˆæ¯åƒæ¬¡å»£å‘Šæ›å…‰æˆæœ¬ï¼‰': 'mean',
        'æ¯æ¬¡è³¼è²·çš„æˆæœ¬': 'mean'
    }).reset_index()

    daily_data.columns = ['æ—¥æœŸ'] + list(daily_data.columns[1:])
    daily_data = daily_data.sort_values('æ—¥æœŸ')

    return daily_data

def create_dual_axis_trend_chart(data, primary_metric, secondary_metric):
    """å‰µå»ºé›™è»¸è¶¨å‹¢åœ–"""
    if data.empty:
        return None

    fig = make_subplots(specs=[[{"secondary_y": True}]])

    # ä¸»è¦æŒ‡æ¨™
    fig.add_trace(
        go.Scatter(
            x=data['æ—¥æœŸ'],
            y=data[primary_metric],
            name=primary_metric,
            line=dict(color='#1f77b4', width=3)
        ),
        secondary_y=False,
    )

    # æ¬¡è¦æŒ‡æ¨™
    if primary_metric != secondary_metric:
        fig.add_trace(
            go.Scatter(
                x=data['æ—¥æœŸ'],
                y=data[secondary_metric],
                name=secondary_metric,
                line=dict(color='#ff7f0e', width=2, dash='dash')
            ),
            secondary_y=True,
        )

    # è¨­å®šè»¸æ¨™ç±¤
    fig.update_xaxes(title_text="æ—¥æœŸ")
    fig.update_yaxes(title_text=primary_metric, secondary_y=False)
    if primary_metric != secondary_metric:
        fig.update_yaxes(title_text=secondary_metric, secondary_y=True)

    fig.update_layout(
        title="é›™è»¸è¶¨å‹¢åˆ†æ",
        height=500,
        hovermode='x unified'
    )

    return fig

def calculate_trend_statistics(data, metric):
    """è¨ˆç®—è¶¨å‹¢çµ±è¨ˆ"""
    if data.empty or len(data) < 2:
        return {'trend_direction': 'ç„¡æ³•è¨ˆç®—', 'change_rate': 0}

    # è¨ˆç®—ç·šæ€§è¶¨å‹¢
    x = np.arange(len(data))
    y = data[metric].values

    # éæ¿¾ç„¡æ•ˆå€¼
    valid_mask = ~np.isnan(y)
    if np.sum(valid_mask) < 2:
        return {'trend_direction': 'æ•¸æ“šä¸è¶³', 'change_rate': 0}

    x_valid = x[valid_mask]
    y_valid = y[valid_mask]

    slope, intercept, r_value, p_value, std_err = stats.linregress(x_valid, y_valid)

    # è¨ˆç®—è®ŠåŒ–ç‡
    start_value = y_valid[0]
    end_value = y_valid[-1]
    change_rate = ((end_value - start_value) / start_value * 100) if start_value != 0 else 0

    # åˆ¤æ–·è¶¨å‹¢æ–¹å‘
    if abs(slope) < 0.01:
        trend_direction = "ç©©å®š"
    elif slope > 0:
        trend_direction = "ä¸Šå‡"
    else:
        trend_direction = "ä¸‹é™"

    return {
        'trend_direction': trend_direction,
        'change_rate': change_rate,
        'slope': slope,
        'r_squared': r_value**2
    }

def create_daily_performance_chart(data):
    """å‰µå»ºæ¯æ—¥è¡¨ç¾åœ–è¡¨"""
    if data.empty:
        return None

    fig = go.Figure()

    # æ·»åŠ  ROAS æ¢ç‹€åœ–
    fig.add_trace(go.Bar(
        x=data['æ—¥æœŸ'],
        y=data['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'],
        name='ROAS',
        marker_color='lightblue',
        yaxis='y'
    ))

    # æ·»åŠ èŠ±è²»æŠ˜ç·šåœ–
    fig.add_trace(go.Scatter(
        x=data['æ—¥æœŸ'],
        y=data['èŠ±è²»é‡‘é¡ (TWD)'],
        name='èŠ±è²»é‡‘é¡',
        line=dict(color='red', width=2),
        yaxis='y2'
    ))

    fig.update_layout(
        title="æ¯æ—¥ ROAS vs èŠ±è²»è¶¨å‹¢",
        xaxis_title="æ—¥æœŸ",
        yaxis=dict(title="ROAS", side="left"),
        yaxis2=dict(title="èŠ±è²»é‡‘é¡ (TWD)", side="right", overlaying="y"),
        height=400,
        showlegend=True
    )

    return fig

def create_moving_average_chart(data, metric, period):
    """å‰µå»ºç§»å‹•å¹³å‡åœ–è¡¨"""
    if data.empty or len(data) < period:
        return None

    # è¨ˆç®—ç§»å‹•å¹³å‡
    data_copy = data.copy()
    data_copy[f'{metric}_MA{period}'] = data_copy[metric].rolling(window=period).mean()

    fig = go.Figure()

    # åŸå§‹æ•¸æ“š
    fig.add_trace(go.Scatter(
        x=data_copy['æ—¥æœŸ'],
        y=data_copy[metric],
        name=f'{metric} (åŸå§‹)',
        line=dict(color='lightgray', width=1),
        opacity=0.7
    ))

    # ç§»å‹•å¹³å‡
    fig.add_trace(go.Scatter(
        x=data_copy['æ—¥æœŸ'],
        y=data_copy[f'{metric}_MA{period}'],
        name=f'{period}æ—¥ç§»å‹•å¹³å‡',
        line=dict(color='blue', width=3)
    ))

    fig.update_layout(
        title=f"{metric} - {period}æ—¥ç§»å‹•å¹³å‡åˆ†æ",
        xaxis_title="æ—¥æœŸ",
        yaxis_title=metric,
        height=400
    )

    return fig

def detect_anomalies(data, metric, threshold=2):
    """æª¢æ¸¬ç•°å¸¸å€¼"""
    if data.empty or len(data) < 3:
        return []

    values = data[metric].values
    mean_val = np.mean(values)
    std_val = np.std(values)

    anomalies = []
    for i, (date, value) in enumerate(zip(data['æ—¥æœŸ'], values)):
        if abs(value - mean_val) > threshold * std_val:
            anomalies.append({
                'date': date,
                'value': value,
                'deviation': abs(value - mean_val) / std_val
            })

    return anomalies

def detect_change_points(data, metric, min_change=0.2):
    """æª¢æ¸¬è¶¨å‹¢è®ŠåŒ–é»"""
    if data.empty or len(data) < 5:
        return []

    values = data[metric].values
    dates = data['æ—¥æœŸ'].values

    change_points = []

    # ä½¿ç”¨æ»‘å‹•çª—å£æª¢æ¸¬è®ŠåŒ–é»
    window_size = 3
    for i in range(window_size, len(values) - window_size):
        before_mean = np.mean(values[i-window_size:i])
        after_mean = np.mean(values[i:i+window_size])

        if before_mean != 0:
            change_percent = (after_mean - before_mean) / before_mean * 100
            if abs(change_percent) > min_change * 100:
                change_points.append({
                    'date': dates[i],
                    'change': change_percent,
                    'before': before_mean,
                    'after': after_mean
                })

    return change_points

def create_change_point_chart(data, metric, change_points):
    """å‰µå»ºè®ŠåŒ–é»åœ–è¡¨"""
    if data.empty:
        return None

    fig = go.Figure()

    # åŸå§‹è¶¨å‹¢ç·š
    fig.add_trace(go.Scatter(
        x=data['æ—¥æœŸ'],
        y=data[metric],
        name=metric,
        line=dict(color='blue', width=2)
    ))

    # æ¨™è¨˜è®ŠåŒ–é»
    if change_points:
        change_dates = [cp['date'] for cp in change_points]
        change_values = []

        for cp_date in change_dates:
            # æ‰¾åˆ°å°æ‡‰çš„å€¼
            matching_row = data[data['æ—¥æœŸ'] == cp_date]
            if not matching_row.empty:
                change_values.append(matching_row[metric].iloc[0])
            else:
                change_values.append(0)

        fig.add_trace(go.Scatter(
            x=change_dates,
            y=change_values,
            mode='markers',
            name='è®ŠåŒ–é»',
            marker=dict(color='red', size=10, symbol='diamond')
        ))

    fig.update_layout(
        title=f"{metric} è¶¨å‹¢è®ŠåŒ–é»åˆ†æ",
        xaxis_title="æ—¥æœŸ",
        yaxis_title=metric,
        height=400
    )

    return fig

def generate_predictions(data, metric, days, model_type):
    """ç”Ÿæˆé æ¸¬"""
    if data.empty or len(data) < 3:
        return None

    try:
        # æº–å‚™æ•¸æ“š
        y = data[metric].values
        X = np.arange(len(y)).reshape(-1, 1)

        # éæ¿¾ç„¡æ•ˆå€¼
        valid_mask = ~np.isnan(y)
        if np.sum(valid_mask) < 3:
            return None

        X_valid = X[valid_mask]
        y_valid = y[valid_mask]

        # é æ¸¬çš„ X å€¼
        future_X = np.arange(len(y), len(y) + days).reshape(-1, 1)

        if model_type == "ç·šæ€§è¿´æ­¸":
            model = LinearRegression()
            model.fit(X_valid, y_valid)
            predictions = model.predict(future_X)

        elif model_type == "å¤šé …å¼è¿´æ­¸":
            poly_features = PolynomialFeatures(degree=2)
            X_poly = poly_features.fit_transform(X_valid)
            future_X_poly = poly_features.transform(future_X)

            model = LinearRegression()
            model.fit(X_poly, y_valid)
            predictions = model.predict(future_X_poly)

        elif model_type == "ç§»å‹•å¹³å‡":
            # ä½¿ç”¨æœ€è¿‘3å¤©çš„ç§»å‹•å¹³å‡
            window = min(3, len(y_valid))
            last_values = y_valid[-window:]
            avg_value = np.mean(last_values)
            predictions = np.full(days, avg_value)

        # ç”Ÿæˆé æ¸¬æ—¥æœŸ
        last_date = data['æ—¥æœŸ'].iloc[-1]
        future_dates = [last_date + timedelta(days=i+1) for i in range(days)]

        # è¿”å›é æ¸¬çµæœ
        prediction_df = pd.DataFrame({
            'æ—¥æœŸ': future_dates,
            'predicted_values': predictions
        })

        return prediction_df

    except Exception as e:
        st.error(f"é æ¸¬è¨ˆç®—å¤±æ•—: {str(e)}")
        return None

def create_prediction_chart(historical_data, predictions, metric):
    """å‰µå»ºé æ¸¬åœ–è¡¨"""
    if historical_data.empty or predictions is None:
        return None

    fig = go.Figure()

    # æ­·å²æ•¸æ“š
    fig.add_trace(go.Scatter(
        x=historical_data['æ—¥æœŸ'],
        y=historical_data[metric],
        name='æ­·å²æ•¸æ“š',
        line=dict(color='blue', width=2)
    ))

    # é æ¸¬æ•¸æ“š
    fig.add_trace(go.Scatter(
        x=predictions['æ—¥æœŸ'],
        y=predictions['predicted_values'],
        name='é æ¸¬å€¼',
        line=dict(color='red', width=2, dash='dash')
    ))

    # åœ¨æ­·å²å’Œé æ¸¬ä¹‹é–“æ·»åŠ é€£æ¥é»
    if not historical_data.empty and not predictions.empty:
        last_historical = historical_data.iloc[-1]
        first_prediction = predictions.iloc[0]

        fig.add_trace(go.Scatter(
            x=[last_historical['æ—¥æœŸ'], first_prediction['æ—¥æœŸ']],
            y=[last_historical[metric], first_prediction['predicted_values']],
            mode='lines',
            line=dict(color='red', width=2, dash='dash'),
            showlegend=False
        ))

    fig.update_layout(
        title=f"{metric} è¶¨å‹¢é æ¸¬",
        xaxis_title="æ—¥æœŸ",
        yaxis_title=metric,
        height=500
    )

    return fig

def calculate_prediction_confidence(data, metric, model_type):
    """è¨ˆç®—é æ¸¬å¯ä¿¡åº¦"""
    if data.empty or len(data) < 5:
        return 0.0

    try:
        # ä½¿ç”¨æœ€å¾Œ5å€‹æ•¸æ“šé»é€²è¡Œäº¤å‰é©—è­‰
        values = data[metric].dropna()
        if len(values) < 5:
            return 0.0

        # è¨ˆç®—æ•¸æ“šçš„ç©©å®šæ€§ï¼ˆè®Šç•°ä¿‚æ•¸çš„å€’æ•¸ï¼‰
        cv = values.std() / values.mean() if values.mean() != 0 else float('inf')
        stability_score = 1 / (1 + cv) if cv != float('inf') else 0.0

        # æ ¹æ“šæ¨¡å‹é¡å‹èª¿æ•´
        model_confidence = {
            "ç·šæ€§è¿´æ­¸": 0.7,
            "å¤šé …å¼è¿´æ­¸": 0.6,
            "ç§»å‹•å¹³å‡": 0.8
        }.get(model_type, 0.5)

        # æ•¸æ“šé‡èª¿æ•´
        data_size_factor = min(len(values) / 10, 1.0)

        confidence = stability_score * model_confidence * data_size_factor
        return min(confidence, 1.0)

    except:
        return 0.0

def analyze_weekly_patterns(data):
    """åˆ†ææ˜ŸæœŸå¹¾çš„è¡¨ç¾æ¨¡å¼"""
    if data.empty:
        return pd.DataFrame()

    data_copy = data.copy()
    data_copy['weekday'] = pd.to_datetime(data_copy['æ—¥æœŸ']).dt.day_name()

    # ä¸­æ–‡æ˜ŸæœŸå¹¾æ˜ å°„
    weekday_map = {
        'Monday': 'æ˜ŸæœŸä¸€',
        'Tuesday': 'æ˜ŸæœŸäºŒ',
        'Wednesday': 'æ˜ŸæœŸä¸‰',
        'Thursday': 'æ˜ŸæœŸå››',
        'Friday': 'æ˜ŸæœŸäº”',
        'Saturday': 'æ˜ŸæœŸå…­',
        'Sunday': 'æ˜ŸæœŸæ—¥'
    }
    data_copy['weekday'] = data_copy['weekday'].map(weekday_map)

    # æŒ‰æ˜ŸæœŸå¹¾åˆ†çµ„èšåˆ
    weekly_stats = data_copy.groupby('weekday').agg({
        'èŠ±è²»é‡‘é¡ (TWD)': 'mean',
        'è³¼è²·æ¬¡æ•¸': 'mean',
        'è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰': 'mean',
        'è§¸åŠäººæ•¸': 'mean'
    }).reset_index()

    # é‡æ–°æ’åºæ˜ŸæœŸå¹¾
    weekday_order = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
    weekly_stats['weekday'] = pd.Categorical(weekly_stats['weekday'], categories=weekday_order, ordered=True)
    weekly_stats = weekly_stats.sort_values('weekday').reset_index(drop=True)

    return weekly_stats

def create_weekly_pattern_chart(weekly_data):
    """å‰µå»ºæ˜ŸæœŸå¹¾è¡¨ç¾åœ–è¡¨"""
    if weekly_data.empty:
        return None

    fig = make_subplots(specs=[[{"secondary_y": True}]])

    # ROAS æ¢ç‹€åœ–
    fig.add_trace(
        go.Bar(
            x=weekly_data['weekday'],
            y=weekly_data['è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰'],
            name='ROAS',
            marker_color='lightblue'
        ),
        secondary_y=False,
    )

    # èŠ±è²»æŠ˜ç·šåœ–
    fig.add_trace(
        go.Scatter(
            x=weekly_data['weekday'],
            y=weekly_data['èŠ±è²»é‡‘é¡ (TWD)'],
            name='å¹³å‡èŠ±è²»',
            line=dict(color='red', width=3),
            mode='lines+markers'
        ),
        secondary_y=True,
    )

    fig.update_xaxes(title_text="æ˜ŸæœŸå¹¾")
    fig.update_yaxes(title_text="ROAS", secondary_y=False)
    fig.update_yaxes(title_text="èŠ±è²»é‡‘é¡ (TWD)", secondary_y=True)

    fig.update_layout(
        title="æ˜ŸæœŸå¹¾è¡¨ç¾åˆ†æ",
        height=400
    )

    return fig

def analyze_time_patterns(data):
    """åˆ†ææ™‚é–“æ¨¡å¼"""
    if data.empty or 'é–‹å§‹' not in data.columns:
        return None

    # æå–å°æ™‚ä¿¡æ¯
    data_copy = data.copy()
    data_copy['hour'] = pd.to_datetime(data_copy['æ—¥æœŸ']).dt.hour

    # çµ±è¨ˆæ¯å°æ™‚çš„è¡¨ç¾
    hourly_stats = data_copy.groupby('hour').agg({
        'è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰': 'mean',
        'èŠ±è²»é‡‘é¡ (TWD)': 'sum'
    }).reset_index()

    # æ‰¾å‡ºæœ€ä½³æ™‚æ®µï¼ˆROAS æœ€é«˜çš„å‰3å€‹å°æ™‚ï¼‰
    top_hours = hourly_stats.nlargest(3, 'è³¼è²· ROASï¼ˆå»£å‘ŠæŠ•è³‡å ±é…¬ç‡ï¼‰')['hour'].tolist()

    return {
        'hourly_stats': hourly_stats,
        'optimal_hours': top_hours
    }

def create_hour_distribution_chart(data):
    """å‰µå»ºå°æ™‚åˆ†ä½ˆåœ–è¡¨"""
    if data.empty:
        return None

    # é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›ä¸Šéœ€è¦æœ‰å°æ™‚ç´šåˆ¥çš„æ•¸æ“š
    # é€™è£¡æˆ‘å€‘å‡è¨­æ‰€æœ‰æ•¸æ“šéƒ½åœ¨å·¥ä½œæ™‚é–“
    hours = list(range(24))
    counts = [np.random.randint(0, 10) for _ in hours]  # æ¨¡æ“¬æ•¸æ“š

    fig = go.Figure(data=go.Bar(x=hours, y=counts))
    fig.update_layout(
        title="å»£å‘ŠæŠ•æ”¾æ™‚é–“åˆ†ä½ˆ",
        xaxis_title="å°æ™‚",
        yaxis_title="æŠ•æ”¾æ¬¡æ•¸",
        height=300
    )

    return fig

if __name__ == "__main__":
    show_trend_analysis()